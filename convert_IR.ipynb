{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa4335f3-2e24-448f-a181-30599edde592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Markdown\n",
    "from openvino.runtime import Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a2ca74e-05dd-4579-adfe-27abb376fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The paths of the source and converted models.\n",
    "model_path = Path(\"models/pb_model/saved_model.pb\")\n",
    "ir_path = Path(model_path).with_suffix(\".xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e88947ff-490d-4f1c-850b-66da6d3ff6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer command to convert TensorFlow to OpenVINO:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "`mo --input_model \"models/pb_model/saved_model.pb\" --input_model_is_text --input_shape \"[1, 10, 24]\" --framework 'tf' --data_type FP16 --output_dir \"models/pb_model\"`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construct the command for Model Optimizer.\n",
    "mo_command = f\"\"\"mo\n",
    "                 --input_model \"{model_path}\"\n",
    "                 --input_model_is_text\n",
    "                 --input_shape \"[1, 10, 24]\"\n",
    "                 --framework 'tf'\n",
    "                 --data_type FP16\n",
    "                 --output_dir \"{model_path.parent}\"\n",
    "                 \"\"\"\n",
    "mo_command = \" \".join(mo_command.split())\n",
    "print(\"Model Optimizer command to convert TensorFlow to OpenVINO:\")\n",
    "display(Markdown(f\"`{mo_command}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29de5c3f-a01c-4f1f-84d0-3c06cd4c2db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting TensorFlow model to IR... This may take a few minutes.\n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/Users/neo/work/voilence_detection/models/pb_model/saved_model.pb\n",
      "\t- Path for generated IR: \t/Users/neo/work/voilence_detection/models/pb_model\n",
      "\t- IR output name: \tsaved_model\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \t[1, 10, 24]\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tNot specified\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- User transformations: \tNot specified\n",
      "\t- Reverse input channels: \tFalse\n",
      "\t- Enable IR generation for fixed input shape: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "Advanced parameters:\n",
      "\t- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "\t- Force the usage of new Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tTrue\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "OpenVINO runtime found in: \t/Users/neo/anaconda3/envs/openvino/lib/python3.8/site-packages/openvino\n",
      "OpenVINO runtime version: \t2022.2.0-7713-af16ea1d79a-releases/2022/2\n",
      "Model Optimizer version: \t2022.2.0-7713-af16ea1d79a-releases/2022/2\n",
      "[ FRAMEWORK ERROR ]  Cannot load input model: TensorFlow cannot read the model file: \"/Users/neo/work/voilence_detection/models/pb_model/saved_model.pb\" is incorrect TensorFlow model file. \n",
      "The file should contain one of the following TensorFlow graphs:\n",
      "1. frozen graph in text or binary format\n",
      "2. inference graph for freezing with checkpoint (--input_checkpoint) in text or binary format\n",
      "3. meta graph\n",
      "\n",
      "Make sure that --input_model_is_text is provided for a model in text format. By default, a model is interpreted in binary format. Framework error details: 'utf-8' codec can't decode byte 0x94 in position 3: invalid start byte. \n",
      " For more information please refer to Model Optimizer FAQ, question #43. (https://docs.openvino.ai/latest/openvino_docs_MO_DG_prepare_model_Model_Optimizer_FAQ.html?question=43#question-43)\n"
     ]
    }
   ],
   "source": [
    "# Run Model Optimizer if the IR model file does not exist\n",
    "if not ir_path.exists():\n",
    "    print(\"Exporting TensorFlow model to IR... This may take a few minutes.\")\n",
    "    ! $mo_command\n",
    "else:\n",
    "    print(f\"IR model {ir_path} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a3bc88-5d60-43df-b67b-65db45bef1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a9d3a3-d2af-4850-bb96-832f17d6f757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e5d32-91da-4a6e-b338-4c024377bd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8790e5-a58a-4e84-bc7f-f3a1ded341cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
