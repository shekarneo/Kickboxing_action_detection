{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install mediapipe\n",
    "# !git config --global http.sslVerify false\n",
    "# !pip install -qr https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "origin_data = glob.glob(r\"archive/Videos/*\")\n",
    "print(len(origin_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "origin_data_violent = glob.glob(r\"archive/Videos/Violent_*\")\n",
    "origin_data_normal = glob.glob(r\"archive/Videos/Normal_*\")\n",
    "print(len(origin_data_violent))\n",
    "print(len(origin_data_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense,Dropout, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "import math\n",
    "import mediapipe as mp\n",
    "from mediapipe.python.solutions import pose as mp_pose\n",
    "import torch\n",
    "from threading import Thread\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5n')\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose =mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lấy keypoint 1 video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_global = 0\n",
    "def EachVideo(linkVideo): # This function is used to cycle through a video\n",
    "    X = []\n",
    "    video_path =r\"\"+ linkVideo  # The path to the data file I use\n",
    "    print(f\"playing : {video_path}\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    skipTime  = 0\n",
    "    skipFrame = 0\n",
    "    while True:    \n",
    "        ret, frame = cap.read()\n",
    "        skipTime = skipTime +1\n",
    "        if not ret:\n",
    "            break\n",
    "        if 1==1:\n",
    "        # if skipTime >= 30: # When skipTime has passed the first 30 frames, ie the first 1 second, proceed to Detect Person\n",
    "            skipFrame = skipFrame +1 # The variable skipFrame means that every 5 frames I will detect 1 time, so in 1 second I will detect 6 times\n",
    "            # print(skipFrame)\n",
    "            # if  skipFrame  == 5: # When skipFrame = 5, I will detect person and assign skipFrame = 0 to run again\n",
    "            if 1==1:\n",
    "                skipFrame = 0\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame.flags.writeable = False  \n",
    "                result = yolo_model(frame)     # Detect Person\n",
    "                frame.flags.writeable = True   \n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "                for (xmin, ymin, xmax,   ymax,  confidence,  clas) in result.xyxy[0].tolist(): # Loop through all the Persons present in the video, giving the x,y of each Person\n",
    "                    c_lm = []\n",
    "                    with mp_pose.Pose(min_detection_confidence=0.3, min_tracking_confidence=0.3) as pose:\n",
    "                            \n",
    "                            # frame.flags.writeable = False  \n",
    "\n",
    "                            resulta = pose.process(frame[int(ymin):int(ymax),int(xmin):int(xmax):])\n",
    "                            # frame.flags.writeable = True   \n",
    "\n",
    "                            if resulta.pose_landmarks and clas==0: # class here is class, class = 0 means human\n",
    "                                for (id, lm) in enumerate(resulta.pose_landmarks.landmark):\n",
    "                                    if id > 10 and id not in [17,18,19,20,21,22] and id not in [29,30,31,32] :\n",
    "                                        c_lm.append(lm.x)\n",
    "                                        c_lm.append(lm.y)\n",
    "                                        # c_lm.append(lm.z)\n",
    "                                        # c_lm.append(lm.visibility)\n",
    "                    if len(c_lm) > 0: # c_ lm used to save a person's x and y variables in a loop through each person, when saving, there will be a state that there is no x,y data to save \n",
    "                        X.append(c_lm) # with linkVideo being violent, we add data to X_violent\n",
    "                # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                #       break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through multiple videos to get keypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AllVideo(startt,endd,dataset): # This function is used to cycle through all videos\n",
    "    # Status (linkVideo) is : violent, non-violent\n",
    "    X = []\n",
    "    \n",
    "    # cam (camIndex) is : cam1 or cam2\n",
    "    # number of videos is : from startt to endd, for example non-violent dataset is startt 1->61 with cam 1, violent from 1 to 115 with cam 1\n",
    "    for id,i in enumerate(range(startt,endd)):\n",
    "        print(f'{startt} -> {endd} ## index: {startt+id}')\n",
    "        X.extend(EachVideo(dataset[i])) # Implement the function to detect\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save keypoint, run getData function to run multiple videos at the same time (threading) to get keypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "def getData(startt,endd,origin_data):\n",
    "    global X\n",
    "    X = AllVideo(startt,endd,origin_data)\n",
    "\n",
    "    \n",
    "active = []\n",
    "skipT = 1500\n",
    "for i in range(0,10):\n",
    "    active_1 = Thread(target=getData,args=(skipT,skipT+20,origin_data_normal))\n",
    "    skipT = skipT + 20\n",
    "    if skipT >= 1600:\n",
    "        break\n",
    "    active.append(active_1)\n",
    "\n",
    "for i in active:\n",
    "    i.start()\n",
    "for i in active:\n",
    "    i.join()\n",
    "    \n",
    "print(len(X))\n",
    "X = np.array(X)\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "\n",
    "# X = []\n",
    "# def getData(startt,endd,origin_data):\n",
    "#     global X\n",
    "#     X = AllVideo(startt,endd,origin_data)\n",
    "\n",
    "    \n",
    "# active = []\n",
    "# skipT = 0\n",
    "# for i in range(0,10):\n",
    "#     active_1 = Thread(target=getData,args=(skipT,skipT+20,origin_data_violent))\n",
    "#     skipT = skipT + 20\n",
    "#     active.append(active_1)\n",
    "\n",
    "# for i in active:\n",
    "#     i.start()\n",
    "# for i in active:\n",
    "#     i.join()\n",
    "    \n",
    "# print(len(X))\n",
    "# X = np.array(X)\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X))\n",
    "Xt = np.array(X)\n",
    "print(Xt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save keypoint to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = pd.DataFrame(Xt)\n",
    "Xt  = np.nan_to_num(Xt) # Khi đã có dữ liệu, sẽ có một số phần từ trong dữ liệu bị NaN, nên chuyển thành 0\n",
    "Xt = pd.DataFrame(Xt)\n",
    "Xt.to_csv(\"./normal_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Crane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violent_1_200 = pd.read_csv(\"voilent_0_650_final.csv\")\n",
    "# violent_200_400 = pd.read_csv(\"../input/subkevin/violent_200_400.csv\")\n",
    "# violent_400_600 = pd.read_csv(\"../input/subkevin/violent_400_600.csv\")\n",
    "\n",
    "normal_1_500 = pd.read_csv(\"normal_2000_2500_final.csv\")\n",
    "normal_500_1000 = pd.read_csv(\"normal_test.csv\")\n",
    "# normal_1000_1500 = pd.read_csv(\"../input/subkevin/normal_1000_1500.csv\")\n",
    "# normal_1500_2000 = pd.read_csv(\"../input/subkevin/normal_1500_2000.csv\")\n",
    "# normal_2000_2500 = pd.read_csv(\"normal_2000_2500_final.csv\")\n",
    "\n",
    "# violent_1_200 = violent_1_200.append(violent_200_400)\n",
    "# violent_1_200 = violent_1_200.append(violent_400_600)\n",
    "\n",
    "\n",
    "normal_1_500 = normal_1_500.append(normal_500_1000)\n",
    "# normal_1_500 = normal_1_500.append(normal_1000_1500)\n",
    "# normal_1_500 = normal_1_500.append(normal_1500_2000)\n",
    "# normal_1_500 = normal_1_500.append(normal_2000_2500)\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "X_violent = violent_1_200.iloc[:,1:].values\n",
    "len_X_violent = len(X_violent)\n",
    "for i in range(10,len_X_violent):\n",
    "    X.append(X_violent[i-10:i,:])\n",
    "    y.append(1)\n",
    "    \n",
    "    \n",
    "X_non_violent = normal_1_500.iloc[:,1:].values\n",
    "len_X_non_violent = len(X_non_violent)\n",
    "for i in range(10,len_X_non_violent):\n",
    "    X.append(X_non_violent[i-10:i,:])\n",
    "    y.append(0)\n",
    "    \n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)    \n",
    "print(violent_1_200.shape)\n",
    "print(normal_1_500.shape)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_violent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../siameseNet/data/normal_testX.npy', X)\n",
    "# np.save('../siameseNet/data/normal_testY.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[1], X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(y.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = Sequential()\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (X.shape[1],X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 12, activation=\"relu\"))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(units = 1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"SGD\",  metrics = ['accuracy'], loss = \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=32, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Visualize the training history to see whether you're overfitting.\n",
    "plt.plot(model.history.history['accuracy'])\n",
    "plt.plot(model.history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "\n",
    "X_test = X.copy()\n",
    "y_test = y.copy()\n",
    "class_names_test = [0, 1]\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"Plots the confusion matrix.\"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=55)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                  horizontalalignment=\"center\",\n",
    "                  color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Classify pose in the TEST dataset using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred = [1 if i > 0.5 else 0 for i in y_pred]\n",
    "\n",
    "# Convert the prediction result to class name\n",
    "# y_pred_label = [class_names_test[i] for i in np.argmax(y_pred, axis=1)]\n",
    "# y_true_label = list(y_test) #[class_names_test[i] for i in y_test]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(cm,\n",
    "                      class_names_test,\n",
    "                      title ='Confusion Matrix of Pose Classification Model')\n",
    "\n",
    "# Print the classification report\n",
    "print('\\nClassification Report:\\n', classification_report(list(y_test), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/tf_k_first.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/pb_model/\", save_format=tf, save_traces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAngle(array_a):\n",
    "    len_a = len(array_a)\n",
    "    len_x  = int(len_a/2)\n",
    "    so_chan = 0\n",
    "    fa = []\n",
    "    for i in range(0,len_x):\n",
    "        fa.append(so_chan)\n",
    "        so_chan = so_chan + 2\n",
    "        \n",
    "    ff = []\n",
    "    dem = 0\n",
    "    sum  = 0\n",
    "    for i in range(4,len_a):\n",
    "        ff.append([])\n",
    "        for j in range(i-4,i+1):\n",
    "            \n",
    "            len_x  = int(len(array_a[j])/2)\n",
    "            for i in range(0,len_x):\n",
    "                fa.append(so_chan)\n",
    "                so_chan = so_chan + 2\n",
    "\n",
    "            for k in range(0,len_x-1):\n",
    "                for m in range(k+1,len_x):\n",
    "                    tru_x =  array_a[j][fa[m]] - array_a[j][fa[k]] \n",
    "                    tru_y = array_a[j][fa[m]+1] -  array_a[j][fa[k]+1]\n",
    "                    if tru_x == 0:\n",
    "                        tru_x=1\n",
    "                    atan = math.atan(tru_y / tru_x)\n",
    "                    ff[dem].append(atan)\n",
    "                    \n",
    "        dem = dem + 1\n",
    "    return ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_1_500_copy = np.copy(normal_1_500)\n",
    "violent_1_200_copy = np.copy(violent_1_200)\n",
    "                             \n",
    "normal_1_500_array = list(normal_1_500_copy)\n",
    "violent_1_200_array = list(violent_1_200_copy)\n",
    "\n",
    "X_model_2_violent  = []\n",
    "X_model_2_violent.extend(getAngle(violent_1_200_array))\n",
    "X_model_2_violent = pd.DataFrame(X_model_2_violent)\n",
    "\n",
    "\n",
    "X_model_2_non_violent = []\n",
    "X_model_2_non_violent.extend(getAngle(normal_1_500_array))\n",
    "X_model_2_non_violent = pd.DataFrame(X_model_2_non_violent)\n",
    "\n",
    "\n",
    "X_2 = list([])\n",
    "y_2 = list([])\n",
    "# print(len(X_model_2_violent))\n",
    "\n",
    "X_model_2_violent =  X_model_2_violent.iloc[:,1:].values\n",
    "len_X_model_2_violent = len(X_model_2_violent)\n",
    "for i in range(10,len_X_model_2_violent):\n",
    "    X_2.append(X_model_2_violent[i-10:i,:])\n",
    "    y_2.append(1)\n",
    "    \n",
    "\n",
    "X_model_2_non_violent =  X_model_2_non_violent.iloc[:,1:].values\n",
    "len_X_model_2_non_violent = len(X_model_2_non_violent)\n",
    "for i in range(10,len_X_model_2_non_violent):\n",
    "    X_2.append(X_model_2_non_violent[i-10:i,:])\n",
    "    y_2.append(0)\n",
    "\n",
    "\n",
    "# y_model_2 = []\n",
    "\n",
    "# len_X_violent = len(violent_1_200_array)\n",
    "# for i in range(10,len_X_violent):\n",
    "#     X_model_2.append(X_violent[i-10:i,:])\n",
    "#     y.append(1)\n",
    "# X = []\n",
    "# y = []\n",
    "X_2 = np.array(X_2)\n",
    "y_2 = np.array(y_2)\n",
    "y_2 = y_2.reshape(y_2.shape[0], -1)\n",
    "\n",
    "print(X_2.shape)\n",
    "print(y_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3  = Sequential()\n",
    "\n",
    "model_3.add(Dense( 500, activation=\"relu\",input_shape = (X_2.shape[1],X_2.shape[2])))\n",
    "model_3.add(Dense( 300, activation=\"relu\"))\n",
    "\n",
    "# model_3.add(LSTM(units = 50, return_sequences = True, input_shape = (X.shape[1],X.shape[2])))\n",
    "model_3.add(Dropout(0.4))\n",
    "\n",
    "model_3.add(Dense( 100, activation=\"relu\"))\n",
    "model_3.add(Dense( 50, activation=\"relu\"))\n",
    "model_3.add(Dropout(0.3))\n",
    "\n",
    "model_3.add(Dense( 25, activation=\"relu\"))\n",
    "model_3.add(Dense( 10, activation=\"relu\"))\n",
    "model_3.add(Dense( 5, activation=\"relu\"))\n",
    "model_3.add(Dense( 1, activation=\"sigmoid\"))\n",
    "model_3.compile(optimizer=\"adam\",  metrics = ['accuracy'], loss = \"binary_crossentropy\")\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_3.fit(X_2, y_2, epochs=32, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data artlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= []\n",
    "y =[]\n",
    "non_violent = pd.read_csv(\"normal_2000_2500_final.csv\")\n",
    "X_non_violent = non_violent.iloc[:,1:].values\n",
    "len_X_non_violent = len(X_non_violent)\n",
    "for i in range(10,len_X_non_violent):\n",
    "  X.append(X_non_violent[i-10:i,:])\n",
    "  y.append(0)\n",
    "violent = pd.read_csv(\"voilent_0_650_final.csv\")\n",
    "X_violent = violent.iloc[:,1:].values\n",
    "len_X_violent = len(X_violent)\n",
    "for i in range(10,len_X_violent):\n",
    "  X.append(X_violent[i-10:i,:])\n",
    "  y.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2  = Sequential()\n",
    "model2.add(LSTM(units = 50, return_sequences = True, input_shape = (X.shape[1],X.shape[2])))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(LSTM(units = 50, return_sequences = True))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(LSTM(units = 50, return_sequences = True))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(units = 4, activation=\"relu\"))\n",
    "model2.add(Dense(units = 1, activation=\"sigmoid\"))\n",
    "model2.compile(optimizer=\"adam\",  metrics = ['accuracy'], loss = \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X, y, epochs=32, batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model_v41.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
